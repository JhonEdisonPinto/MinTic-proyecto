"""AnÃ¡lisis de CSV de siniestros y respuesta de preguntas con Gemini.

Este mÃ³dulo proporciona funciones para:
- Cargar datos de CSV
- Extraer metadatos y estadÃ­sticas
- Responder preguntas sobre los datos usando Gemini

Casos de uso:
- Analizar datos de siniestros desde CSV
- Generar reportes automÃ¡ticos
- Responder preguntas sobre patrones en los datos
"""
import os
import logging
from pathlib import Path
from typing import Dict, Any, Optional
import pandas as pd

logger = logging.getLogger(__name__)


def load_csv_dataset(csv_path: str) -> pd.DataFrame:
    """Cargar CSV y devolver DataFrame con informaciÃ³n sobre carga."""
    path = Path(csv_path)
    if not path.exists():
        raise FileNotFoundError(f"CSV no encontrado: {csv_path}")
    
    df = pd.read_csv(path)
    logger.info(f"âœ“ CSV cargado: {csv_path} ({len(df)} filas, {len(df.columns)} columnas)")
    return df


def extract_dataset_metadata(df: pd.DataFrame) -> Dict[str, Any]:
    """Extrae metadatos y estadÃ­sticas del DataFrame.
    
    Retorna un diccionario con:
    - shape: (filas, columnas)
    - columns: nombres y tipos de datos
    - missing: porcentaje de valores nulos por columna
    - numeric_stats: min, max, mean para columnas numÃ©ricas
    - unique_values: count de valores Ãºnicos por columna
    """
    metadata = {
        "shape": df.shape,
        "columns": list(df.columns),
        "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
        "missing_percent": {col: (df[col].isna().sum() / len(df) * 100) for col in df.columns},
        "unique_counts": {col: df[col].nunique() for col in df.columns},
        "numeric_stats": {},
        "categorical_samples": {},
    }
    
    # EstadÃ­sticas numÃ©ricas
    numeric_cols = df.select_dtypes(include=["number"]).columns
    for col in numeric_cols:
        metadata["numeric_stats"][col] = {
            "min": float(df[col].min()) if not df[col].isna().all() else None,
            "max": float(df[col].max()) if not df[col].isna().all() else None,
            "mean": float(df[col].mean()) if not df[col].isna().all() else None,
            "median": float(df[col].median()) if not df[col].isna().all() else None,
        }
    
    # Muestras de valores categÃ³ricos
    categorical_cols = df.select_dtypes(include=["object"]).columns
    for col in categorical_cols:
        top_values = df[col].value_counts().head(5).to_dict()
        metadata["categorical_samples"][col] = top_values
    
    return metadata


def generate_dataset_report(df: pd.DataFrame, metadata: Optional[Dict] = None) -> str:
    """Genera un reporte textual del dataset para pasarlo a Gemini."""
    if metadata is None:
        metadata = extract_dataset_metadata(df)
    
    rows, cols = metadata["shape"]
    report = f"""
=== REPORTE DEL DATASET ===

ðŸ“Š DIMENSIONES:
- Filas: {rows:,}
- Columnas: {cols}

ðŸ“‹ COLUMNAS Y TIPOS:
"""
    
    for col, dtype in metadata["dtypes"].items():
        missing = metadata["missing_percent"].get(col, 0)
        unique = metadata["unique_counts"].get(col, 0)
        report += f"  â€¢ {col:<35} | Tipo: {dtype:<10} | Nulos: {missing:.1f}% | Ãšnicos: {unique}\n"
    
    # EstadÃ­sticas numÃ©ricas
    if metadata["numeric_stats"]:
        report += "\nðŸ“ˆ ESTADÃSTICAS NUMÃ‰RICAS:\n"
        for col, stats in metadata["numeric_stats"].items():
            if stats["min"] is not None:
                report += f"  â€¢ {col:<35} | Min: {stats['min']:<10.2f} | Max: {stats['max']:<10.2f} | Promedio: {stats['mean']:<10.2f}\n"
    
    # Muestras categÃ³ricas
    if metadata["categorical_samples"]:
        report += "\nðŸ·ï¸  VALORES FRECUENTES (CATEGÃ“RICOS):\n"
        for col, top_values in metadata["categorical_samples"].items():
            report += f"  â€¢ {col}:\n"
            for val, count in list(top_values.items())[:3]:
                report += f"      - {val}: {count} registros\n"
    
    return report


def query_dataset_with_gemini(question: str, df: pd.DataFrame, llm=None) -> str:
    """Responde una pregunta sobre un dataset usando Gemini."""
    from src.mintic_project.langchain_integration import LangChainConfig
    
    if llm is None:
        config = LangChainConfig()
        llm = config.crear_llm()
        if llm is None:
            return "âš ï¸  No hay LLM disponible. Configura GEMINI_API_KEY."
    
    logger.info(f"â“ Pregunta sobre datos: {question}")
    
    # Generar reporte del dataset
    metadata = extract_dataset_metadata(df)
    report = generate_dataset_report(df, metadata)
    
    # Crear prompt
    prompt = f"""Eres un experto en anÃ¡lisis de datos. Se te proporciona un reporte detallado de un dataset con informaciÃ³n sobre siniestros viales.

REPORTE DEL DATASET:
{report}

PREGUNTA: {question}

INSTRUCCIONES:
- Responde basÃ¡ndote en el reporte del dataset
- Si necesitas informaciÃ³n mÃ¡s detallada, puedes hacer suposiciones razonables basadas en los datos
- SÃ© preciso y proporciona nÃºmeros cuando sea posible
- Si la pregunta no puede responderse con la informaciÃ³n disponible, indÃ­calo claramente
"""
    
    try:
        logger.info("â³ Generando respuesta con Gemini...")
        response = llm.invoke(prompt)
        
        if hasattr(response, "content"):
            return response.content
        return str(response)
    except Exception as e:
        logger.error(f"âŒ Error generando respuesta: {e}")
        return "âš ï¸  Error al generar la respuesta."


def analyze_csv_file(csv_path: str, question: str = None, llm=None) -> Dict[str, Any]:
    """FunciÃ³n principal: carga CSV, extrae metadata, y opcionalmente responde preguntas.
    
    Args:
        csv_path: Ruta al archivo CSV
        question: Pregunta opcional sobre los datos
        llm: Instancia de LLM (si None, se crea una)
    
    Returns:
        Dict con metadata, report, y respuesta (si pregunta se proporcionÃ³)
    """
    df = load_csv_dataset(csv_path)
    metadata = extract_dataset_metadata(df)
    report = generate_dataset_report(df, metadata)
    
    result = {
        "file": csv_path,
        "shape": metadata["shape"],
        "columns": metadata["columns"],
        "metadata": metadata,
        "report": report,
    }
    
    if question:
        result["question"] = question
        result["answer"] = query_dataset_with_gemini(question, df, llm)
    
    return result


if __name__ == "__main__":
    # Prueba: analizar los CSVs disponibles
    csv_files = [
        "data/siniestros_1_limpio.csv",
        "data/siniestros_2_limpio.csv",
    ]
    
    for csv_path in csv_files:
        if Path(csv_path).exists():
            print(f"\n{'='*80}")
            print(f"ANALIZANDO: {csv_path}")
            print('='*80)
            
            result = analyze_csv_file(
                csv_path,
                question="Â¿CuÃ¡l es el tipo de siniestro mÃ¡s frecuente?",
            )
            
            print(result["report"])
            if "answer" in result:
                print(f"\nðŸ’¬ RESPUESTA A LA PREGUNTA:\n{result['answer']}\n")
