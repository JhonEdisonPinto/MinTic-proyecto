# Sistema de PredicciÃ³n de Siniestros Viales - MinTIC

## ğŸ“Š DescripciÃ³n del Sistema

Este sistema procesa datos abiertos de siniestros viales en Palmira desde **datos.gov.co**, limpia los datos, realiza ingenierÃ­a de caracterÃ­sticas y entrena modelos predictivos con integraciÃ³n a LangChain para crear un **sistema multiagente de predicciÃ³n**.

## ğŸ¯ Objectivos

1. âœ… Descargar datos de dos APIs pÃºblicas de datos.gov.co
2. âœ… Limpiar y validar datos (2000+ registros)
3. âœ… IngenierÃ­a de caracterÃ­sticas para predicciÃ³n
4. âœ… Entrenar modelos de ML (Random Forest, etc.)
5. âœ… IntegraciÃ³n con LangChain para RAG (Retrieval-Augmented Generation)
6. âœ… Sistema multiagente para anÃ¡lisis y predicciÃ³n

## ğŸ“ Estructura de Archivos

```
MinTic-proyecto/
â”œâ”€â”€ src/mintic_project/
â”‚   â”œâ”€â”€ data_loader.py          # Descarga y limpieza de datos
â”‚   â”œâ”€â”€ feature_engineering.py  # IngenierÃ­a de caracterÃ­sticas
â”‚   â””â”€â”€ processor.py            # Utilidades de procesamiento
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion.ipynb                  # Setup inicial
â”‚   â”œâ”€â”€ 02_analisis_siniestros.ipynb          # EDA y visualizaciones
â”‚   â””â”€â”€ 03_multiagente_langchain.ipynb        # PredicciÃ³n con ML + LangChain
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ descargar_datos.py      # Script ejecutable para descargar datos
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_loader.py     # Tests unitarios
â””â”€â”€ data/                       # Directorio de salida (se crea automÃ¡ticamente)
    â”œâ”€â”€ siniestros_1_limpio.csv
    â”œâ”€â”€ siniestros_2_limpio.csv
    â”œâ”€â”€ siniestros_procesados.parquet
    â”œâ”€â”€ reporte_limpieza.txt
    â””â”€â”€ contexto_rag.json
```

## ğŸš€ Quick Start

### 1. Instalar dependencias

```powershell
# En Windows (PowerShell)
.\setup.bat

# O manualmente
pip install -r requirements.txt
pip install pytest scikit-learn
```

### 2. Descargar y limpiar datos

```powershell
# OpciÃ³n A: Usar el script
python scripts/descargar_datos.py

# OpciÃ³n B: Desde el notebook
# Abrir notebooks/02_analisis_siniestros.ipynb y ejecutar
```

### 3. Analizar datos

```powershell
# Iniciar Jupyter
jupyter notebook notebooks/02_analisis_siniestros.ipynb
```

### 4. Entrenar modelo predictivo

```powershell
# Abrir el notebook de LangChain
jupyter notebook notebooks/03_multiagente_langchain.ipynb
```

## ğŸ“‹ Fuentes de Datos

### Dataset 1: Siniestros Viales BÃ¡sicos
- **URL**: `https://www.datos.gov.co/resource/sjpx-eqfp.json`
- **Columnas**: a_o, ipat, clase_siniestro, fecha, hora, jornada, dia_semana, barrios, direcciÃ³n, zona, autoridad, lat, long, hipotesis, cÃ³digo, condiciÃ³n_vÃ­ctima, edad, gÃ©nero, lesionados_muertos
- **Registros**: ~50,000+

### Dataset 2: Siniestros - Gravedad y VÃ­ctimas
- **URL**: `https://www.datos.gov.co/resource/xx6f-f84h.json`
- **Columnas**: gravedad, fecha, a_o, hora, jornada, dia_semana, barrios, direcciÃ³n, zona, autoridad, lat, long, condiciÃ³n_vÃ­ctima, clase_siniestro, gÃ©nero, lesionado, homicidios, clÃ­nica, clase_vehÃ­culo, marca, tipo_servicio, empresa
- **Registros**: ~2000+

## ğŸ§¹ Proceso de Limpieza de Datos

El mÃ³dulo `data_loader.py` ejecuta los siguientes pasos:

### 1. **EliminaciÃ³n de Duplicados**
   - Elimina filas completamente duplicadas

### 2. **ValidaciÃ³n de Tipos de Datos**
   - Convierte `fecha` a datetime
   - Convierte columnas numÃ©ricas a float

### 3. **Limpieza de Valores Nulos**
   - Elimina filas sin informaciÃ³n crÃ­tica (fecha, aÃ±o, localizaciÃ³n)
   - Reporta % de nulos por columna

### 4. **EliminaciÃ³n de Outliers**
   - Edades vÃ¡lidas: 0-120
   - Coordenadas geogrÃ¡ficas: dentro de Palmira (~-3.5Â° a -4.0Â° S, -76.2Â° a -76.5Â° O)

### 5. **EstandarizaciÃ³n de Texto**
   - Elimina espacios extras
   - Convierte categorÃ­as a mayÃºsculas (GÃ‰NERO, JORNADA, ZONA, etc.)

### 6. **ValidaciÃ³n de Rangos**
   - Horas: 0-23
   - ValidaciÃ³n lÃ³gica de campos

## ğŸ”¬ Feature Engineering

El mÃ³dulo `feature_engineering.py` crea caracterÃ­sticas avanzadas:

### 1. **Features Temporales**
   - `mes`: Mes del aÃ±o (1-12)
   - `trimestre`: Trimestre (1-4)
   - `semana_ano`: Semana del aÃ±o
   - `periodo_dia`: MANANA, TARDE, NOCHE, MADRUGADA

### 2. **Features GeogrÃ¡ficos**
   - `distancia_centro`: Distancia euclidiana al centro de Palmira
   - `en_centro`: Binario (1=dentro del centro, 0=fuera)

### 3. **Features CategÃ³ricos Codificados**
   - Label encoding de: jornada, dÃ­a_semana, gÃ©nero, zona, clase_siniestro, gravedad
   - Columnas: `{nombre}_encoded`

### 4. **Features de InteracciÃ³n**
   - `hora_jornada_interaction`: InteracciÃ³n hora Ã— perÃ­odo del dÃ­a
   - `genero_edad_interaction`: InteracciÃ³n gÃ©nero Ã— edad

### 5. **NormalizaciÃ³n**
   - StandardScaler para features numÃ©ricos
   - Columnas: `{nombre}_normalized`

## ğŸ¤– IntegraciÃ³n con LangChain

### Contexto para RAG (Retrieval-Augmented Generation)

El sistema genera contextos estructurados para usar con LangChain:

```python
contexto_rag = {
    "general": "Dataset info (registros, perÃ­odo, columnas)",
    "jornada": "DistribuciÃ³n por jornada",
    "dia_semana": "DistribuciÃ³n por dÃ­a de semana",
    "genero": "DistribuciÃ³n por gÃ©nero",
    "gravedad": "DistribuciÃ³n por gravedad",
    "edad": "EstadÃ­sticas de edad",
}
```

### Ejemplo de Uso

```python
from langchain.llms import OpenAI
from mintic_project.feature_engineering import DatasetPredictor

# Cargar datos procesados
predictor = DatasetPredictor()
df_proc = predictor.preparar_dataset_completo(df1, df2)
contexto = predictor.generar_contexto_rag(df_proc)

# Usar con LangChain
llm = OpenAI(api_key="tu-clave")
prompt = f"""
Contexto: {contexto['general']}
DistribuciÃ³n por jornada: {contexto['jornada']}

Pregunta: Â¿CuÃ¡ndo ocurren mÃ¡s siniestros en Palmira?
"""
respuesta = llm(prompt)
print(respuesta)
```

## ğŸ“Š Modelos de ML

El notebook `03_multiagente_langchain.ipynb` entrena:

### Random Forest Classifier
- **Target**: Gravedad del siniestro (leve, moderado, grave, etc.)
- **Features**: CaracterÃ­sticas temporales, geogrÃ¡ficas, categÃ³ricas
- **MÃ©trica**: Accuracy

### Importancia de Features
El modelo identifica quÃ© variables son mÃ¡s predictivas:
- Jornada y hora
- DÃ­a de la semana
- Zona geogrÃ¡fica
- GÃ©nero y edad

## ğŸ§ª Tests

Ejecutar tests unitarios:

```powershell
# Tests bÃ¡sicos
pytest tests/test_data_loader.py -v

# Con cobertura
pytest tests/test_data_loader.py --cov=src --cov-report=html
```

## ğŸ“ˆ Ejemplo de Output

```
Reporte de Limpieza de Datos
==============================================================

Dataset 1 (Siniestros Viales):
  Registros iniciales: 50000
  Registros finales:   45200
  Registros eliminados: 4800
  % Retenido: 90.4%

Dataset 2 (Gravedad/VÃ­ctimas):
  Registros iniciales: 50000
  Registros finales:   46100
  Registros eliminados: 3900
  % Retenido: 92.2%

==============================================================
```

## ğŸ” Variables de Entorno

Crear archivo `.env`:

```env
# Para LangChain + OpenAI (opcional)
OPENAI_API_KEY="sk-..."

# URLs de APIs (ya configuradas por defecto)
DATA_SOURCE_URL="https://www.datos.gov.co/resource/sjpx-eqfp.json"
```

## ğŸš¦ PrÃ³ximos Pasos

1. **Sistema Multiagente Completo**
   - Crear agentes especializados (anÃ¡lisis temporal, geogrÃ¡fico, predicciÃ³n)
   - Integrar con LangChain Agents

2. **RAG con Normas de TrÃ¡nsito**
   - Incorporar documento con CÃ³digo Nacional de TrÃ¡nsito
   - Vectorizar con embeddings
   - Responder preguntas normativas sobre siniestros

3. **API REST**
   - Crear endpoints con Flask para consultas de predicciÃ³n
   - Integrar con Streamlit Cloud

4. **Dashboard Interactivo**
   - Visualizaciones en tiempo real
   - Filtros por zona, jornada, perÃ­odo

## ğŸ¤ Contribuir

Ver [`CONTRIBUTING.md`](../CONTRIBUTING.md) para detalles.

## ğŸ“š Referencias

- [datos.gov.co](https://www.datos.gov.co/)
- [Pandas Documentation](https://pandas.pydata.org/)
- [LangChain Docs](https://python.langchain.com/)
- [Scikit-learn](https://scikit-learn.org/)
- [Streamlit](https://docs.streamlit.io/)

## ğŸ“ Licencia

MIT License
